{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kuntalpal/few-baselines-without-much-effort?scriptVersionId=115139571\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"%%capture\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-30T12:05:07.703961Z","iopub.execute_input":"2022-12-30T12:05:07.705095Z","iopub.status.idle":"2022-12-30T12:05:19.03743Z","shell.execute_reply.started":"2022-12-30T12:05:07.705035Z","shell.execute_reply":"2022-12-30T12:05:19.035961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Physics behind Protein Stability","metadata":{}},{"cell_type":"markdown","source":"**DDG** : Delta Delta G (DDG) is a metric for predicting how a single point mutation will affect protein stability. The thermodynamic stability change upon mutation is measured by ΔΔG(T$_{r}$), i.e. the difference between the standard Gibbs folding free energies of the mutant (ΔG$^{mut}$) and wild-type (ΔG$^{wild}$) proteins at the reference temperature T$_{r}$:\n\n$$  ΔΔG(T_{r}) = (ΔG^{mut})(T_{r}) - (ΔG^{wild})(T_{r}) $$\n\nIn general,\n\n$$ G = Enthalpy \\ \\  (H) - Temperature \\ \\ (T) \\ x \\ Entropy \\ \\ (S)  $$\n\nH is the internal energy of a protein. H decreases during protein folding because folding will cause packing of hydrophobics, optimized polar group orientation, and achieves a good proximity to ideal bond lengths and angles. S is the measure of order within a system. S of a protein becomes lower during protein folding because residue dynamics will be significantly decreased in comparison the unfolded state. However, decrease is in protein S will also cause an increase in S for solvent. The energy of an unfolded protein is nearly identical with a single point mutation. So, the\ndominant factor in DDG is the energy difference of the folded state.\n","metadata":{}},{"cell_type":"markdown","source":"DDG results will fall into three categories:\n\n1. **DDG > 0.5**: Positive results suggest that a mutation would be destabilizing. Most mutations will be positive or close to zero because proteins have evolved to be reasonably stable. These mutations are residues that you should usually avoid during design.\n\n2. Things that are near 0 are within the noise range so should be considered neutral.\n\n3. DDG < -0.5: Negative results suggest that the mutation would lead to a more stable protein. However, the environment at each position should be considered.\n\n    a. If interacting molecules are not present in the model, such as at a known zinc binding site, then a seemingly favorable mutation will not be favorable in reality.\n    \n    b. A positions that has a lot of negative DDGs could mean that this position evolved a destabilizing residue because it is necessary for its catalytic activity, for binding another molecule, or because of another functionally relevant reason.\n    \n    c. Also, consider that this measures a single point mutation. Many times it requires multiple interacting mutations in order to achieve significant stability.","metadata":{}},{"cell_type":"markdown","source":"# ESM-2\n\nESM-2 is a transformer-based language model, and uses an attention mechanism to learn interaction patterns between pairs of amino acids in the input sequence.\n\nThe larger the value of the attention, the more impactful would be any mutation at that location. So the melting temperature is inversely proportional to the sum of the contact attentions.","metadata":{}},{"cell_type":"code","source":"# # latest release\n# !pip install fair-esm","metadata":{"execution":{"iopub.status.busy":"2022-12-30T12:05:19.040079Z","iopub.execute_input":"2022-12-30T12:05:19.04044Z","iopub.status.idle":"2022-12-30T12:05:19.050882Z","shell.execute_reply.started":"2022-12-30T12:05:19.040408Z","shell.execute_reply":"2022-12-30T12:05:19.047347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #set the edit_idx\n# import pandas as pd, numpy as np, nltk\n# from sklearn.model_selection import GroupKFold\n# import torch\n# import esm\n#wt = \"VPVNPEPDATSVENVALKTGSGDSQSDPIKADLEVKGQSALPFDVDCWAILCKGAPNVLQRVNEKTKNSNRDRSGANKGPFKDPQKWGIKALPPKNPSWSAQDFKSPEEYAFASSLQGGTNAILAPVNLASQNSQGGVLNGFYSANKVAQFDPSKPQQTKGTWFQITKFTGAAGPYCKALGSNDKSVCDKNKNIAGDWGFDPAKWAYQYDEKNNKFNYVGK\"\n#df_test = pd.read_csv(\"../input/novozymes-enzyme-stability-prediction/test.csv\")\n#df_test.loc[1169, 'protein_sequence'] = wt[:-1]+\"!\" #1169 is the same as wt\n\n#df_test['edit_idx'] = df_test.apply(lambda x:[i for i in range(len(x['protein_sequence'])) if x['protein_sequence'][i] != wt[i]][0], axis = 1)\n\n\n# # Load ESM-2 model\n# model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n# batch_converter = alphabet.get_batch_converter()\n# model.eval()  # disables dropout for deterministic results\n\n\n# # Prepare data (first 2 sequences from ESMStructuralSplitDataset superfamily / 4)\n# data = [\n#     (\"protein1\", wt),\n# ]\n# batch_labels, batch_strs, batch_tokens = batch_converter(data)\n\n# # Extract per-residue representations (on CPU)\n# with torch.no_grad():\n#     results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n# token_representations = results[\"representations\"][33]\n\n# # Generate per-sequence representations via averaging\n# # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n# sequence_representations = []\n# for i, (_, seq) in enumerate(data):\n#     sequence_representations.append(token_representations[i, 1 : len(seq) + 1].mean(0))\n\n    \n# #all the code above is from ESM QuickStart\n# ac_sum = np.sum(np.array(results[\"contacts\"][0]), axis=1) \n# test_df['tm'] = test_df.apply(lambda x:1/ac_sum[x['edit_idx']], axis = 1)  \n# test_df[['seq_id', 'tm']].set_index(\"seq_id\").to_csv(\"submission.csv\")\n#df_test","metadata":{"execution":{"iopub.status.busy":"2022-12-30T12:05:19.054737Z","iopub.execute_input":"2022-12-30T12:05:19.055827Z","iopub.status.idle":"2022-12-30T12:05:19.065027Z","shell.execute_reply.started":"2022-12-30T12:05:19.055767Z","shell.execute_reply":"2022-12-30T12:05:19.062809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using Thermonet","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/nesp-public-train-sets/Q3214/Q3214_direct.csv')\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-12-30T12:05:19.067388Z","iopub.execute_input":"2022-12-30T12:05:19.068122Z","iopub.status.idle":"2022-12-30T12:05:19.107183Z","shell.execute_reply.started":"2022-12-30T12:05:19.068075Z","shell.execute_reply":"2022-12-30T12:05:19.105835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install Levenshtein\nimport math\nimport multiprocessing\nimport os\nimport sys\n\nimport Levenshtein\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport sklearn.model_selection\nimport tensorflow as tf\nfrom keras import layers, callbacks\nfrom keras import models\nfrom keras import optimizers\nfrom sklearn.model_selection import GroupKFold\nfrom keras.saving.save import load_model\nfrom tqdm import tqdm","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef gen_mutations(name, df,\n                  wild=\"VPVNPEPDATSVENVALKTGSGDSQSDPIKADLEVKGQSALPFDVDCWAILCKGAPNVLQ\"\"RVNEKTKNSNRDRSGANKGPFKDPQKWGIKALPPKNPSWSAQDFKSPEEYAFASSLQGGT\"\"NAILAPVNLASQNSQGGVLNGFYSANKVAQFDPSKPQQTKGTWFQITKFTGAAGPYCKAL\"\"GSNDKSVCDKNKNIAGDWGFDPAKWAYQYDEKNNKFNYVGK\"):\n    result = []\n    for _, r in df.iterrows():\n        ops = Levenshtein.editops(wild, r.protein_sequence)\n        assert len(ops) <= 1\n        if len(ops) > 0 and ops[0][0] == 'replace':\n            idx = ops[0][1]\n            result.append([ops[0][0], idx + 1, wild[idx], r.protein_sequence[idx]])\n        elif len(ops) == 0:\n            result.append(['same', 0, '', ''])\n        elif ops[0][0] == 'insert':\n            assert False, \"Ups\"\n        elif ops[0][0] == 'delete':\n            idx = ops[0][1]\n            result.append(['delete', idx + 1, wild[idx], '-'])\n        else:\n            assert False, \"Ups\"\n\n    df = pd.concat([df, pd.DataFrame(data=result, columns=['op', 'idx', 'wild', 'mutant'])], axis=1)\n    df['mut'] = df[['wild', 'idx', 'mutant']].astype(str).apply(lambda v: ''.join(v), axis=1)\n    df['name'] = name\n    return df\n\n\ndf_test = gen_mutations('wildtypeA', pd.read_csv('../input/novozymes-enzyme-stability-prediction/test.csv'))\ndf_test","metadata":{"execution":{"iopub.status.busy":"2022-12-30T12:05:19.114748Z","iopub.execute_input":"2022-12-30T12:05:19.115681Z","iopub.status.idle":"2022-12-30T12:05:19.437952Z","shell.execute_reply.started":"2022-12-30T12:05:19.11564Z","shell.execute_reply":"2022-12-30T12:05:19.437076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_FEATURES_PATH = '../input/thermonet-features/Q3214.npy'\nX = np.load(TRAIN_FEATURES_PATH)\nX = np.moveaxis(X, 1, -1)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-30T12:05:19.441886Z","iopub.execute_input":"2022-12-30T12:05:19.444359Z","iopub.status.idle":"2022-12-30T12:05:22.542473Z","shell.execute_reply.started":"2022-12-30T12:05:19.444321Z","shell.execute_reply":"2022-12-30T12:05:22.541433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pdb_ids = df_train.pdb_id\ny = df_train.ddg","metadata":{"execution":{"iopub.status.busy":"2022-12-30T12:05:22.544054Z","iopub.execute_input":"2022-12-30T12:05:22.544466Z","iopub.status.idle":"2022-12-30T12:05:22.549987Z","shell.execute_reply.started":"2022-12-30T12:05:22.544428Z","shell.execute_reply":"2022-12-30T12:05:22.548893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gen_model(params):\n    def build_model(params):\n        conv_layer_sizes = params['conv_layer_sizes']\n        dense_layer_size = params['dense_layer_size']\n        dropout_rate = params['dropout_rate']\n        model = models.Sequential()\n        model.add(layers.Conv3D(filters=conv_layer_sizes[0], kernel_size=(3, 3, 3), input_shape=(16, 16, 16, 14)))\n        model.add(layers.Activation(activation='relu'))\n\n        for ls in conv_layer_sizes[1:]:\n            model.add(layers.Conv3D(filters=ls, kernel_size=(3, 3, 3)))\n            model.add(layers.Activation(activation='relu'))\n\n        model.add(layers.MaxPooling3D(pool_size=(2, 2, 2)))\n        model.add(layers.Flatten())\n\n        model.add(layers.Dropout(rate=dropout_rate))\n        model.add(layers.Dense(units=dense_layer_size, activation='relu'))\n        model.add(layers.Dropout(rate=dropout_rate))\n        model.add(layers.Dense(units=1))\n        return model\n\n    model = build_model(params)\n    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(\n        learning_rate=params['learning_rate'],\n        beta_1=0.9,\n        beta_2=0.999,\n        amsgrad=False\n    ), metrics=['mae'])\n    return model\n\n\ndef train_model(X_train, y_train, X_val, y_val, params, path):\n    model = gen_model(params)\n    scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=\"val_loss\",\n        factor=params['scheduler_factor'],\n        patience=params['scheduler_patience'],\n        verbose=0,\n        mode=\"auto\",\n        min_delta=0.0001,\n        cooldown=0,\n        min_lr=1e-5,\n    )\n\n    checkpoint = callbacks.ModelCheckpoint(path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=params['early_stopping_patience'])\n    result = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n                       epochs=EPOCHS, batch_size=params['batch_size'], verbose=1, callbacks=[scheduler, checkpoint, early_stopping])\n    return load_model(path), result\n\nN_FOLDS = 10\nGROUP_KFOLD = False\nEPOCHS = 200\nMODELS_PATH = 'models'\n\n\n\n\nPARAMS = {\n    'conv_layer_sizes': (16, 32, 64),\n    'dense_layer_size': 24,\n    'dropout_rate': 0.5,\n    'learning_rate': 0.001,\n    'batch_size': 8,\n    'scheduler_patience': 10,\n    'scheduler_factor': math.sqrt(0.1),\n    'early_stopping_patience': 20,\n}\n\n\n!mkdir -p models\nkfold = GroupKFold(N_FOLDS)\nthermonet_models = []\nval_losses = []\nif GROUP_KFOLD:\n    groups = pdb_ids\nelse:\n    groups = range(len(pdb_ids))\n\nfor fold, (train_idx, val_idx) in enumerate(tqdm(kfold.split(X, y, groups=groups), total=N_FOLDS, desc=\"Folds\")):\n    X_train = X[train_idx]\n    y_train = y[train_idx]\n    X_val = X[val_idx]\n    y_val = y[val_idx]\n    path = f'{MODELS_PATH}/model{fold}.h5'\n    model, result = train_model(X_train, y_train, X_val, y_val, PARAMS, path)\n    thermonet_models.append(model)\n    val_losses.append(result.history['val_loss'])","metadata":{"execution":{"iopub.status.busy":"2022-12-30T12:05:22.55189Z","iopub.execute_input":"2022-12-30T12:05:22.552688Z","iopub.status.idle":"2022-12-30T12:17:34.122433Z","shell.execute_reply.started":"2022-12-30T12:05:22.552651Z","shell.execute_reply":"2022-12-30T12:17:34.120536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv = 0.\nfor l in val_losses:\n    plt.plot(l)\n    cv += np.min(l)\n\nplt.title(f\"CV MSE loss: {cv / len(val_losses):.03f}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-30T12:17:34.125282Z","iopub.execute_input":"2022-12-30T12:17:34.127637Z","iopub.status.idle":"2022-12-30T12:17:34.360679Z","shell.execute_reply.started":"2022-12-30T12:17:34.127588Z","shell.execute_reply":"2022-12-30T12:17:34.359689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nthermonet_models = [load_model(f) for f in glob.glob(f'{MODELS_PATH}/model*.h5')]","metadata":{"execution":{"iopub.status.busy":"2022-12-30T12:17:34.362013Z","iopub.execute_input":"2022-12-30T12:17:34.362691Z","iopub.status.idle":"2022-12-30T12:17:34.911617Z","shell.execute_reply.started":"2022-12-30T12:17:34.362651Z","shell.execute_reply":"2022-12-30T12:17:34.910612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_FEATURES_PATH = '../input/thermonet-features/nesp_features.npy'\nif not os.path.exists(TEST_FEATURES_PATH):    \n    np.save(thermonet_features(df_test.query('op == \"replace\"')), 'test_features.npy')\n    TEST_FEATURES_PATH = 'test_features.npy'","metadata":{"execution":{"iopub.status.busy":"2022-12-30T12:17:34.913635Z","iopub.execute_input":"2022-12-30T12:17:34.914007Z","iopub.status.idle":"2022-12-30T12:17:34.922044Z","shell.execute_reply.started":"2022-12-30T12:17:34.91397Z","shell.execute_reply":"2022-12-30T12:17:34.921003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_features = np.load(TEST_FEATURES_PATH)\ntest_features = np.moveaxis(test_features, 1, -1)","metadata":{"execution":{"iopub.status.busy":"2022-12-30T12:17:34.923699Z","iopub.execute_input":"2022-12-30T12:17:34.924273Z","iopub.status.idle":"2022-12-30T12:17:42.447084Z","shell.execute_reply.started":"2022-12-30T12:17:34.924229Z","shell.execute_reply":"2022-12-30T12:17:42.4449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ddg = np.stack([model.predict(test_features) for model in thermonet_models])\ntest_ddg = np.mean(test_ddg, axis=0).flatten()\ntest_ddg","metadata":{"execution":{"iopub.status.busy":"2022-12-30T12:17:42.448675Z","iopub.execute_input":"2022-12-30T12:17:42.449064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.loc[df_test.op == 'replace', 'ddg'] = -test_ddg\ndf_test.loc[df_test['op'] == \"delete\", 'ddg'] = df_test[df_test[\"op\"]==\"replace\"][\"ddg\"].quantile(q=0.25)\ndf_test.loc[df_test['op'] == \"same\", 'ddg'] = 0.\ndf_test.rename(columns={'ddg': 'tm'})[['seq_id', 'tm']].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!head submission.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}