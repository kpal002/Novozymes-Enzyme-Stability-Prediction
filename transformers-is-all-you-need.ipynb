{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kuntalpal/transformers-is-all-you-need?scriptVersionId=113045023\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-05T23:50:29.20235Z","iopub.execute_input":"2022-12-05T23:50:29.203073Z","iopub.status.idle":"2022-12-05T23:50:29.266151Z","shell.execute_reply.started":"2022-12-05T23:50:29.203004Z","shell.execute_reply":"2022-12-05T23:50:29.265162Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/protbert/mymodel.h5\n/kaggle/input/novozymes-enzyme-stability-prediction/sample_submission.csv\n/kaggle/input/novozymes-enzyme-stability-prediction/wildtype_structure_prediction_af2.pdb\n/kaggle/input/novozymes-enzyme-stability-prediction/train.csv\n/kaggle/input/novozymes-enzyme-stability-prediction/test.csv\n/kaggle/input/novozymes-enzyme-stability-prediction/train_updates_20220929.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This notebook uses the pretrained language models ProtTrans [Link](https://github.com/agemagician/ProtTrans). ProtTrans was trained on thousands of GPUs from Summit and hundreds of Google TPUs using Transformers Models.","metadata":{}},{"cell_type":"markdown","source":"1. Load necessry libraries including huggingface and bertvis transformers","metadata":{}},{"cell_type":"code","source":"import re\nimport os\nimport random\nimport pickle\nimport math\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\n# from tensorflow.keras.layers import TextVectorization\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom transformers import TFBertForMaskedLM, BertTokenizer\nfrom matplotlib import rcParams\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n# Scipy's implementation of Spearman's Rho \nfrom scipy.stats import spearmanr\n\nfrom skopt import BayesSearchCV\nseed = 42","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:50:29.26834Z","iopub.execute_input":"2022-12-05T23:50:29.269037Z","iopub.status.idle":"2022-12-05T23:50:56.872471Z","shell.execute_reply.started":"2022-12-05T23:50:29.268984Z","shell.execute_reply":"2022-12-05T23:50:56.871422Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2022-12-05 23:50:45.955813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:45.956750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:45.957774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:45.958568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:45.959364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:45.960103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:45.963835: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-05 23:50:46.226778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:46.227857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:46.228733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:46.229597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:46.230383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:46.231096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:56.042490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:56.043406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:56.044222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:56.045162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:56.045942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:56.046636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13351 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-12-05 23:50:56.051342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 23:50:56.052030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13351 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!pip install torchmetrics\n!pip install pytorch-nlp\n!pip install -q transformers\n!git clone https://github.com/jessevig/bertviz.git","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:50:56.87409Z","iopub.execute_input":"2022-12-05T23:50:56.875043Z","iopub.status.idle":"2022-12-05T23:51:42.263578Z","shell.execute_reply.started":"2022-12-05T23:50:56.875005Z","shell.execute_reply":"2022-12-05T23:51:42.261928Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything(1234)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:42.26689Z","iopub.execute_input":"2022-12-05T23:51:42.26723Z","iopub.status.idle":"2022-12-05T23:51:42.273988Z","shell.execute_reply.started":"2022-12-05T23:51:42.267183Z","shell.execute_reply":"2022-12-05T23:51:42.272841Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/novozymes-enzyme-stability-prediction/train.csv')\ndf_test = pd.read_csv(\"../input/novozymes-enzyme-stability-prediction/test.csv\")\nsample = pd.read_csv('../input/novozymes-enzyme-stability-prediction/sample_submission.csv')\n\nprint(f\"train_shape:{df_train.shape},test_shape:{df_test.shape},Sample_shape:{sample.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:42.276107Z","iopub.execute_input":"2022-12-05T23:51:42.276718Z","iopub.status.idle":"2022-12-05T23:51:42.761589Z","shell.execute_reply.started":"2022-12-05T23:51:42.276681Z","shell.execute_reply":"2022-12-05T23:51:42.760534Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"train_shape:(31390, 5),test_shape:(2413, 4),Sample_shape:(2413, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Make corrections to data 2409 rows, with all features marked as NaN), \n# as well as the rows where the pH and tm were transposed \n# (25 rows, with corrected features in this dataset)\n\nimport pandas as pd\n\ndf_train_updates = pd.read_csv(\"../input/novozymes-enzyme-stability-prediction/train_updates_20220929.csv\", index_col=\"seq_id\")\n\nall_features_nan = df_train_updates.isnull().all(\"columns\")\n\ndrop_indices = df_train_updates[all_features_nan].index\ndf_train = df_train.drop(index=drop_indices)\n\nswap_ph_tm_indices = df_train_updates[~all_features_nan].index\ndf_train.loc[swap_ph_tm_indices, [\"pH\", \"tm\"]] = df_train_updates.loc[swap_ph_tm_indices, [\"pH\", \"tm\"]]","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:42.762852Z","iopub.execute_input":"2022-12-05T23:51:42.763198Z","iopub.status.idle":"2022-12-05T23:51:42.813049Z","shell.execute_reply.started":"2022-12-05T23:51:42.76317Z","shell.execute_reply":"2022-12-05T23:51:42.812058Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:42.816025Z","iopub.execute_input":"2022-12-05T23:51:42.81661Z","iopub.status.idle":"2022-12-05T23:51:43.147242Z","shell.execute_reply.started":"2022-12-05T23:51:42.816572Z","shell.execute_reply":"2022-12-05T23:51:43.146268Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 4\nBUFFER_SIZE = 5000\nAUTO = tf.data.AUTOTUNE\nEPOCHS = 100\nMAX_LEN = 512\nPAD_TYPE = 'post'\nTRUNC_TYPE = 'post'\nCHECKPOINT_PATH = '/kaggle/input/protbert/mymodel.h5'","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:43.149167Z","iopub.execute_input":"2022-12-05T23:51:43.149792Z","iopub.status.idle":"2022-12-05T23:51:43.156297Z","shell.execute_reply.started":"2022-12-05T23:51:43.149754Z","shell.execute_reply":"2022-12-05T23:51:43.155047Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def preprocess(data):\n    seq = \" \".join(\"\".join(data.split()))\n    seq = re.sub(r\"[UZOB]\", \"X\", seq)\n\n    return seq","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:43.158022Z","iopub.execute_input":"2022-12-05T23:51:43.159305Z","iopub.status.idle":"2022-12-05T23:51:43.167587Z","shell.execute_reply.started":"2022-12-05T23:51:43.159247Z","shell.execute_reply":"2022-12-05T23:51:43.166516Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\")\nprint(f\"{tokenizer.get_vocab()}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:43.173672Z","iopub.execute_input":"2022-12-05T23:51:43.173968Z","iopub.status.idle":"2022-12-05T23:51:45.008472Z","shell.execute_reply.started":"2022-12-05T23:51:43.173931Z","shell.execute_reply":"2022-12-05T23:51:45.007319Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/81.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bc77d81cd2a41b1942b75e2c1558bcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"216d711b85aa40afb1a96ff6c65a736e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/86.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1b5e2901234db7a0e11d60e15b3f11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/361 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4acd65a63f70430e9377fb2ec5b1501f"}},"metadata":{}},{"name":"stdout","text":"{'[PAD]': 0, '[UNK]': 1, '[CLS]': 2, '[SEP]': 3, '[MASK]': 4, 'L': 5, 'A': 6, 'G': 7, 'V': 8, 'E': 9, 'S': 10, 'I': 11, 'K': 12, 'R': 13, 'D': 14, 'T': 15, 'P': 16, 'N': 17, 'Q': 18, 'F': 19, 'Y': 20, 'M': 21, 'H': 22, 'C': 23, 'W': 24, 'X': 25, 'U': 26, 'B': 27, 'Z': 28, 'O': 29}\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(df_train['protein_sequence'], df_train['tm'], test_size=0.15, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:45.011089Z","iopub.execute_input":"2022-12-05T23:51:45.012499Z","iopub.status.idle":"2022-12-05T23:51:45.024457Z","shell.execute_reply.started":"2022-12-05T23:51:45.012435Z","shell.execute_reply":"2022-12-05T23:51:45.022897Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def prot_encode(texts, tokenizer, max_len = MAX_LEN):\n    input_ids = np.zeros((len(texts), max_len), dtype=\"int32\")\n    #token_type_ids = np.zeros((len(texts), max_len), dtype=\"int32\")\n    attention_mask = np.zeros((len(texts), max_len), dtype=\"int32\")\n    \n    for i, text in enumerate(texts):\n        text = preprocess(text)\n        token = tokenizer(text, \n                          max_length         = max_len, \n                          truncation         = True, \n                          padding            = \"max_length\",\n                          add_special_tokens = True,\n                          return_tensors     = \"np\")\n        \n        input_ids[i] = token['input_ids']\n        #token_type_ids[i] = token['token_type_ids']\n        attention_mask[i] = token['attention_mask']\n    return input_ids, attention_mask   #token_type_ids, ","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:45.026462Z","iopub.execute_input":"2022-12-05T23:51:45.026858Z","iopub.status.idle":"2022-12-05T23:51:45.035996Z","shell.execute_reply.started":"2022-12-05T23:51:45.026823Z","shell.execute_reply":"2022-12-05T23:51:45.034911Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#X_train = prot_encode(X_train.astype(str), tokenizer)\n#X_valid = prot_encode(X_valid.astype(str), tokenizer)\n\n#y_train = y_train.values\n#y_valid = y_valid.values","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:45.037975Z","iopub.execute_input":"2022-12-05T23:51:45.038518Z","iopub.status.idle":"2022-12-05T23:51:45.047907Z","shell.execute_reply.started":"2022-12-05T23:51:45.03847Z","shell.execute_reply":"2022-12-05T23:51:45.046974Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((X_train, y_train))\n    .repeat()\n    .shuffle(2048)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((X_valid, y_valid))\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:45.05109Z","iopub.execute_input":"2022-12-05T23:51:45.051406Z","iopub.status.idle":"2022-12-05T23:51:45.114195Z","shell.execute_reply.started":"2022-12-05T23:51:45.051379Z","shell.execute_reply":"2022-12-05T23:51:45.113144Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"X_test = prot_encode(df_test['protein_sequence'].astype(str), tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:45.116382Z","iopub.execute_input":"2022-12-05T23:51:45.116947Z","iopub.status.idle":"2022-12-05T23:51:51.022899Z","shell.execute_reply.started":"2022-12-05T23:51:45.116911Z","shell.execute_reply":"2022-12-05T23:51:51.021908Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"for x, y in train_dataset.take(1):\n    print(x)\n    print(y)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:51.024401Z","iopub.execute_input":"2022-12-05T23:51:51.024751Z","iopub.status.idle":"2022-12-05T23:51:51.085065Z","shell.execute_reply.started":"2022-12-05T23:51:51.024717Z","shell.execute_reply":"2022-12-05T23:51:51.084166Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[b'MSMSQSRAVQRSSSPNEDRGENQLVVYDLKGNDDTEEEVLPVQSQPLSSRTQCPSIGAFTVQCASCFKWRLMPSMQKYEEIREQLLENPFFCDTAREWKPDISCDVPADIYQDGTRLWAIDKPNISRPPAGWQRLLRIRGEGGTRFADVYYVAPSGKKLRSTVEVQKYLNDNSEYIGEGVKLSQFSFQIPKPLQDDYVRKRPARLLDSIDNTNTPVAKEANPLAWISPDDHISLQLGTPTESGLNNSHYQPSKKKKTSTLSIFGSNDELAD'\n b'MALLTAAARLFGAKNASCLVLAARHASASSTNLKDILADLIPKEQARIKTFRQQHGNTVVGQITVDMMYGGMRGMKGLVYETSVLDPDEGIRFRGYSIPECQKMLPKAKGGEEPLPEGLFWLLVTGQIPTEEQVSWLSKEWAKRAALPSHVVTMLDNFPTNLHPMSQLSAAITALNSESNFARAYAEGIHRTKYWELIYEDCMDLIAKLPCVAAKIYRNLYREGSSIGAIDSKLDWSHNFTNMLGYTDAQFTELMRLYLTIHSDHEGGNVSAHTSHLVGSALSDPYLSFAAAMNGLAGPLGGLANQEVLVWLTQLQKEVGKDVSDEKLRDYIWNTLNSGRVVPGYGHAVLRKTDPRYTCQREFALKHLPHDPMFKLVAQLYKIVPNVLLEQGKAKNPWPNVDAHSGVLLQYYGMTEMNYYTVLFGVSRALGVLAQLIWSRALGFPLERPKSMSTDGLIKLVDSK'\n b'MSGKVVLHYFNGRGKMESIRWLLAAAGVQFEEVFLTEKEQFDKLLSDGALTFQQVPLVEIDGMKLVQSKAILNYIAGKYNLYGKDLKERAMIDIYSEGLIDLMEMIMVSPFTPAENKEKVFSNIEEKAKVRFLPVFEKALANSSFLVGKQLSRADVHLLEATLMLQELFPSILATFPKIQAFQEQMKALPAISKFLQPGSARKPPPDEEYARTVKAVLSHLF'\n b'MYNIPDNVKGAVEFDPWLKPFADVLSERRYLADKWLYDITHATPDGSYQSLSKFARDSYKSYGLHANPETKEITYKEWAPNAERAFLVGDFNNWDTTSHELKNKDEFGNFTITLHPLPNGDFAIPHDSKIKVMFILPDGSKIFRLPAWITRATQPSKETSKQFGPAYEGRFWNPENPYKFVHPRPKFSESVDSLRIYEAHVGISSPEPKITTYKEFTEKVLPRIKYLGYDAIQLMAIMEHAYYASFGYQVTNFFAASSRFGTPEELKELIDTAHSMGILVLLDVVHSHASKNVEDGLNMFDGSDHQYFHSISSGRGEHPLWDSRLFNYGKFEVQRFLLANLAFYVDVYQFDGFRFDGVTSMLYVHHGVGAGGSFSGDYNEYLSRDRSFVDHEALAYLMLANDLVHEMLPNLAVTVAEDVSGYPTLCLPRSIGGTGFDYRLAMALPDMWIKLIKEKKDDEWEMGSIVYTLTNRRYGEKVVAYCESHDQALVGDKTLAFWLMDAAMYTDMTVLKEPSIVIDRGIALHKMIRLITHSLGGEAYLNFEGNEFGHPEWLDFPNVNNGDSYKYARRQFNLADDPLLRYQNLNEFDRSMQLCEKRHKWLNTKQAYVSLKHEGDKMIVFERNNLLFIFNFHPTNSYSDYRVGVEKAGTYHIVLNSDRAEFGGHNRINESSEFFTTDLEWNNRKNFLQVYIPSRVALVLALK'], shape=(4,), dtype=string)\ntf.Tensor([47.6 56.  46.5 53.5], shape=(4,), dtype=float64)\n","output_type":"stream"}]},{"cell_type":"code","source":"model_checkpoint_callback = keras.callbacks.ModelCheckpoint(CHECKPOINT_PATH,\n                                                           monitor='val_loss',\n                                                           save_best_only=True,\n                                                           save_weights_only=True)\n\nearlystop_callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                  patience=10,\n                                                  verbose=1)\n\nreducelr_callback = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                     factor=0.2,\n                                                     patience=5,\n                                                     verbose=1)\n\n# define your custom callback for prediction\nclass CustomCallback(keras.callbacks.Callback):\n    def __init__(self, model, x_test):\n        self.model = model\n        self.x_test = x_test\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred = self.model.predict(self.x_test)\n        print('y predicted: ', y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:51.087242Z","iopub.execute_input":"2022-12-05T23:51:51.087979Z","iopub.status.idle":"2022-12-05T23:51:51.096322Z","shell.execute_reply.started":"2022-12-05T23:51:51.087943Z","shell.execute_reply":"2022-12-05T23:51:51.095297Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def build_model(trainable=True,max_len=512):\n    base_model = TFBertForMaskedLM.from_pretrained(\"Rostlab/prot_bert\", from_pt=True)\n    base_model.trainable = trainable\n    #for i in range(6,13):\n    #    base_model.bert.encoder.layer[i].trainable = False\n    input_ids = keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n\n    attention_mask = keras.Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n    base_output = base_model.bert(input_ids=input_ids,attention_mask=attention_mask)\n    last_hidden_state = base_output[0]\n    x = layers.GlobalAveragePooling1D()(last_hidden_state)\n    x = layers.Dense(512, activation='relu')(x)\n    x = layers.Dropout(0.15)(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dropout(0.1)(x)\n    outputs = layers.Dense(1)(x)\n    model = keras.Model(inputs=[input_ids, attention_mask], outputs=outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:51.098053Z","iopub.execute_input":"2022-12-05T23:51:51.098445Z","iopub.status.idle":"2022-12-05T23:51:51.112367Z","shell.execute_reply.started":"2022-12-05T23:51:51.098412Z","shell.execute_reply":"2022-12-05T23:51:51.11132Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nwith strategy.scope():\n\n    model = build_model(trainable=False)  # freeze base model\n\n    model.compile(optimizer=keras.optimizers.Adam(3e-5),\n                loss=keras.losses.MeanSquaredError(),\n                metrics=[keras.losses.MeanAbsoluteError()])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:51:51.114163Z","iopub.execute_input":"2022-12-05T23:51:51.114469Z","iopub.status.idle":"2022-12-05T23:53:08.327655Z","shell.execute_reply.started":"2022-12-05T23:51:51.114437Z","shell.execute_reply":"2022-12-05T23:53:08.326635Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.57G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b28325fb4174f3dae91dda05b8f2b4d"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForMaskedLM: ['cls.predictions.decoder.bias']\n- This IS expected if you are initializing TFBertForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertForMaskedLM were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\nattention_mask (InputLayer)     [(None, 512)]        0                                            \n__________________________________________________________________________________________________\nbert (TFBertMainLayer)          TFBaseModelOutputWit 418881536   input_ids[0][0]                  \n                                                                 attention_mask[0][0]             \n__________________________________________________________________________________________________\nglobal_average_pooling1d (Globa (None, 1024)         0           bert[0][0]                       \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 512)          524800      global_average_pooling1d[0][0]   \n__________________________________________________________________________________________________\ndropout_91 (Dropout)            (None, 512)          0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 256)          131328      dropout_91[0][0]                 \n__________________________________________________________________________________________________\ndropout_92 (Dropout)            (None, 256)          0           dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1)            257         dropout_92[0][0]                 \n==================================================================================================\nTotal params: 419,537,921\nTrainable params: 656,385\nNon-trainable params: 418,881,536\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#callbacks = [ \n#    model_checkpoint_callback,\n#    earlystop_callback,\n#    reducelr_callback,\n#    CustomCallback(model, X_test)\n#]\n\n#history = model.fit(train_dataset,\n#                    validation_data=valid_dataset,\n#                    epochs=3,\n#                    callbacks=callbacks,\n#                    steps_per_epoch=y_train.shape[0]//BATCH_SIZE,\n#                   )","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:53:08.329324Z","iopub.execute_input":"2022-12-05T23:53:08.329857Z","iopub.status.idle":"2022-12-05T23:53:08.334756Z","shell.execute_reply.started":"2022-12-05T23:53:08.329818Z","shell.execute_reply":"2022-12-05T23:53:08.333537Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"model.load_weights(CHECKPOINT_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:53:08.336249Z","iopub.execute_input":"2022-12-05T23:53:08.337245Z","iopub.status.idle":"2022-12-05T23:53:23.741049Z","shell.execute_reply.started":"2022-12-05T23:53:08.337201Z","shell.execute_reply":"2022-12-05T23:53:23.739749Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loss = history.history['loss']\n#epoch = range(len(loss) + len(history.history[\"loss\"]))\n\n#plt.plot(epoch, history.history['loss']+history.history[\"loss\"])\n#plt.plot(epoch, history.history['val_loss']+history.history[\"val_loss\"])\n\n#plt.figure()\n#plt.plot(epoch, history.history['mean_absolute_error']+history.history[\"mean_absolute_error\"])\n#plt.plot(epoch, history.history['val_mean_absolute_error']+history.history[\"val_mean_absolute_error\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:53:23.743099Z","iopub.execute_input":"2022-12-05T23:53:23.745555Z","iopub.status.idle":"2022-12-05T23:53:23.750662Z","shell.execute_reply.started":"2022-12-05T23:53:23.745501Z","shell.execute_reply":"2022-12-05T23:53:23.749463Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(X_test,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T23:53:23.752023Z","iopub.execute_input":"2022-12-05T23:53:23.75245Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"2022-12-05 23:53:23.910632: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\nop: \"FlatMapDataset\"\ninput: \"PrefetchDataset/_8\"\nattr {\n  key: \"Targuments\"\n  value {\n    list {\n    }\n  }\n}\nattr {\n  key: \"f\"\n  value {\n    func {\n      name: \"__inference_Dataset_flat_map_slice_batch_indices_29264\"\n    }\n  }\n}\nattr {\n  key: \"output_shapes\"\n  value {\n    list {\n      shape {\n        dim {\n          size: -1\n        }\n      }\n    }\n  }\n}\nattr {\n  key: \"output_types\"\n  value {\n    list {\n      type: DT_INT64\n    }\n  }\n}\n. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n2022-12-05 23:53:23.948041: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"17/76 [=====>........................] - ETA: 2:19","output_type":"stream"}]},{"cell_type":"code","source":"submission_df = pd.DataFrame()\nsubmission_df[\"seq_id\"] = df_test[\"seq_id\"]\nsubmission_df[\"tm\"] = predictions\nsubmission_df.to_csv(\"submission.csv\", index=False)\npd.read_csv('submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}