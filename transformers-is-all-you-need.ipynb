{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kuntalpal/transformers-is-all-you-need?scriptVersionId=113140655\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-06T23:43:04.534472Z","iopub.execute_input":"2022-12-06T23:43:04.534877Z","iopub.status.idle":"2022-12-06T23:43:04.545647Z","shell.execute_reply.started":"2022-12-06T23:43:04.534832Z","shell.execute_reply":"2022-12-06T23:43:04.544667Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"/kaggle/input/novozymes-enzyme-stability-prediction/sample_submission.csv\n/kaggle/input/novozymes-enzyme-stability-prediction/wildtype_structure_prediction_af2.pdb\n/kaggle/input/novozymes-enzyme-stability-prediction/train.csv\n/kaggle/input/novozymes-enzyme-stability-prediction/test.csv\n/kaggle/input/novozymes-enzyme-stability-prediction/train_updates_20220929.csv\n/kaggle/input/protbert3/model_2.h5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This notebook uses the pretrained language models ProtTrans [Link](https://github.com/agemagician/ProtTrans). ProtTrans was trained on thousands of GPUs from Summit and hundreds of Google TPUs using Transformers Models.","metadata":{}},{"cell_type":"markdown","source":"1. Load necessry libraries including huggingface and bertvis transformers","metadata":{}},{"cell_type":"code","source":"import re\nimport os\nimport random\nimport pickle\nimport math\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\n# from tensorflow.keras.layers import TextVectorization\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom transformers import TFBertForMaskedLM, BertTokenizer\nfrom matplotlib import rcParams\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n# Scipy's implementation of Spearman's Rho \nfrom scipy.stats import spearmanr\n\nfrom skopt import BayesSearchCV\nseed = 42","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:04.547509Z","iopub.execute_input":"2022-12-06T23:43:04.548104Z","iopub.status.idle":"2022-12-06T23:43:04.556013Z","shell.execute_reply.started":"2022-12-06T23:43:04.548071Z","shell.execute_reply":"2022-12-06T23:43:04.554952Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install torchmetrics\n!pip install pytorch-nlp\n!pip install -q transformers\n!git clone https://github.com/jessevig/bertviz.git","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:04.557576Z","iopub.execute_input":"2022-12-06T23:43:04.557846Z","iopub.status.idle":"2022-12-06T23:43:29.82774Z","shell.execute_reply.started":"2022-12-06T23:43:04.557816Z","shell.execute_reply":"2022-12-06T23:43:29.8266Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything(1234)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:29.830109Z","iopub.execute_input":"2022-12-06T23:43:29.831047Z","iopub.status.idle":"2022-12-06T23:43:29.838191Z","shell.execute_reply.started":"2022-12-06T23:43:29.830988Z","shell.execute_reply":"2022-12-06T23:43:29.837601Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    \n    strategy = tf.distribute.experimental.TPUStrategy\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() \n    print('Number of replicas:', strategy.num_replicas_in_sync) ","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:29.839776Z","iopub.execute_input":"2022-12-06T23:43:29.840281Z","iopub.status.idle":"2022-12-06T23:43:35.817418Z","shell.execute_reply.started":"2022-12-06T23:43:29.840239Z","shell.execute_reply":"2022-12-06T23:43:35.816697Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"2022-12-06 23:43:29.851846: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2022-12-06 23:43:29.852378: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n2022-12-06 23:43:29.860866: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2022-12-06 23:43:29.861261: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n","output_type":"stream"}]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\nexcept ValueError:\n    tpu = None\n    gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n    \nif tpu:\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu,) \n    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nelif len(gpus) > 1:\n    strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n    print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\nelif len(gpus) == 1:\n    strategy = tf.distribute.get_strategy() \n    print('Running on single GPU ', gpus[0].name)\nelse:\n    strategy = tf.distribute.get_strategy() \n    print('Running on CPU')\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:35.818503Z","iopub.execute_input":"2022-12-06T23:43:35.818756Z","iopub.status.idle":"2022-12-06T23:43:45.887961Z","shell.execute_reply.started":"2022-12-06T23:43:35.818729Z","shell.execute_reply":"2022-12-06T23:43:45.887223Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Running on TPU  ['10.0.0.2:8470']\nNumber of accelerators:  8\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/novozymes-enzyme-stability-prediction/train.csv')\ndf_test = pd.read_csv(\"../input/novozymes-enzyme-stability-prediction/test.csv\")\nsample = pd.read_csv('../input/novozymes-enzyme-stability-prediction/sample_submission.csv')\n\nprint(f\"train_shape:{df_train.shape},test_shape:{df_test.shape},Sample_shape:{sample.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:45.889491Z","iopub.execute_input":"2022-12-06T23:43:45.890294Z","iopub.status.idle":"2022-12-06T23:43:46.367134Z","shell.execute_reply.started":"2022-12-06T23:43:45.890257Z","shell.execute_reply":"2022-12-06T23:43:46.366007Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"train_shape:(31390, 5),test_shape:(2413, 4),Sample_shape:(2413, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Make corrections to data 2409 rows, with all features marked as NaN), \n# as well as the rows where the pH and tm were transposed \n# (25 rows, with corrected features in this dataset)\n\nimport pandas as pd\n\ndf_train_updates = pd.read_csv(\"../input/novozymes-enzyme-stability-prediction/train_updates_20220929.csv\", index_col=\"seq_id\")\n\nall_features_nan = df_train_updates.isnull().all(\"columns\")\n\ndrop_indices = df_train_updates[all_features_nan].index\ndf_train = df_train.drop(index=drop_indices)\n\nswap_ph_tm_indices = df_train_updates[~all_features_nan].index\ndf_train.loc[swap_ph_tm_indices, [\"pH\", \"tm\"]] = df_train_updates.loc[swap_ph_tm_indices, [\"pH\", \"tm\"]]","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:46.368704Z","iopub.execute_input":"2022-12-06T23:43:46.368993Z","iopub.status.idle":"2022-12-06T23:43:46.396726Z","shell.execute_reply.started":"2022-12-06T23:43:46.368963Z","shell.execute_reply":"2022-12-06T23:43:46.395739Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:46.397854Z","iopub.execute_input":"2022-12-06T23:43:46.398441Z","iopub.status.idle":"2022-12-06T23:43:46.402814Z","shell.execute_reply.started":"2022-12-06T23:43:46.398411Z","shell.execute_reply":"2022-12-06T23:43:46.401612Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 4\nBUFFER_SIZE = 5000\nAUTO = tf.data.AUTOTUNE\nEPOCHS = 100\nMAX_LEN = 512\nPAD_TYPE = 'post'\nTRUNC_TYPE = 'post'\nCHECKPOINT_PATH = '/kaggle/input/protbert3/model_2.h5'","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:46.405766Z","iopub.execute_input":"2022-12-06T23:43:46.406009Z","iopub.status.idle":"2022-12-06T23:43:46.414282Z","shell.execute_reply.started":"2022-12-06T23:43:46.405984Z","shell.execute_reply":"2022-12-06T23:43:46.41345Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def preprocess(data):\n    seq = \" \".join(\"\".join(data.split()))\n    seq = re.sub(r\"[UZOB]\", \"X\", seq)\n\n    return seq","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:46.415255Z","iopub.execute_input":"2022-12-06T23:43:46.415516Z","iopub.status.idle":"2022-12-06T23:43:46.428682Z","shell.execute_reply.started":"2022-12-06T23:43:46.415486Z","shell.execute_reply":"2022-12-06T23:43:46.427711Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\")\nprint(f\"{tokenizer.get_vocab()}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:46.429853Z","iopub.execute_input":"2022-12-06T23:43:46.430302Z","iopub.status.idle":"2022-12-06T23:43:47.309598Z","shell.execute_reply.started":"2022-12-06T23:43:46.430274Z","shell.execute_reply":"2022-12-06T23:43:47.308688Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"{'[PAD]': 0, '[UNK]': 1, '[CLS]': 2, '[SEP]': 3, '[MASK]': 4, 'L': 5, 'A': 6, 'G': 7, 'V': 8, 'E': 9, 'S': 10, 'I': 11, 'K': 12, 'R': 13, 'D': 14, 'T': 15, 'P': 16, 'N': 17, 'Q': 18, 'F': 19, 'Y': 20, 'M': 21, 'H': 22, 'C': 23, 'W': 24, 'X': 25, 'U': 26, 'B': 27, 'Z': 28, 'O': 29}\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(df_train['protein_sequence'], df_train['tm'], test_size=0.15, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:47.311128Z","iopub.execute_input":"2022-12-06T23:43:47.311616Z","iopub.status.idle":"2022-12-06T23:43:47.325268Z","shell.execute_reply.started":"2022-12-06T23:43:47.311573Z","shell.execute_reply":"2022-12-06T23:43:47.32445Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def prot_encode(texts, tokenizer, max_len = MAX_LEN):\n    input_ids = np.zeros((len(texts), max_len), dtype=\"int32\")\n    #token_type_ids = np.zeros((len(texts), max_len), dtype=\"int32\")\n    attention_mask = np.zeros((len(texts), max_len), dtype=\"int32\")\n    \n    for i, text in enumerate(texts):\n        text = preprocess(text)\n        token = tokenizer(text, \n                          max_length         = max_len, \n                          truncation         = True, \n                          padding            = \"max_length\",\n                          add_special_tokens = True,\n                          return_tensors     = \"np\")\n        \n        input_ids[i] = token['input_ids']\n        #token_type_ids[i] = token['token_type_ids']\n        attention_mask[i] = token['attention_mask']\n    return input_ids, attention_mask   #token_type_ids, ","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:47.326342Z","iopub.execute_input":"2022-12-06T23:43:47.3266Z","iopub.status.idle":"2022-12-06T23:43:47.3343Z","shell.execute_reply.started":"2022-12-06T23:43:47.326571Z","shell.execute_reply":"2022-12-06T23:43:47.333018Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#X_train = prot_encode(X_train.astype(str), tokenizer)\n#X_valid = prot_encode(X_valid.astype(str), tokenizer)\n\n#y_train = y_train.values\n#y_valid = y_valid.values","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:47.335427Z","iopub.execute_input":"2022-12-06T23:43:47.335695Z","iopub.status.idle":"2022-12-06T23:43:47.345314Z","shell.execute_reply.started":"2022-12-06T23:43:47.335663Z","shell.execute_reply":"2022-12-06T23:43:47.34436Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((X_train, y_train))\n    .repeat()\n    .shuffle(2048)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((X_valid, y_valid))\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:47.346643Z","iopub.execute_input":"2022-12-06T23:43:47.347125Z","iopub.status.idle":"2022-12-06T23:43:47.424909Z","shell.execute_reply.started":"2022-12-06T23:43:47.347089Z","shell.execute_reply":"2022-12-06T23:43:47.423853Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"X_test = prot_encode(df_test['protein_sequence'].astype(str), tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:47.426248Z","iopub.execute_input":"2022-12-06T23:43:47.426749Z","iopub.status.idle":"2022-12-06T23:43:53.212826Z","shell.execute_reply.started":"2022-12-06T23:43:47.426714Z","shell.execute_reply":"2022-12-06T23:43:53.211738Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"for x, y in train_dataset.take(1):\n    print(x)\n    print(y)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:53.21463Z","iopub.execute_input":"2022-12-06T23:43:53.216511Z","iopub.status.idle":"2022-12-06T23:43:53.243478Z","shell.execute_reply.started":"2022-12-06T23:43:53.216451Z","shell.execute_reply":"2022-12-06T23:43:53.242589Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[b'MSMSQSRAVQRSSSPNEDRGENQLVVYDLKGNDDTEEEVLPVQSQPLSSRTQCPSIGAFTVQCASCFKWRLMPSMQKYEEIREQLLENPFFCDTAREWKPDISCDVPADIYQDGTRLWAIDKPNISRPPAGWQRLLRIRGEGGTRFADVYYVAPSGKKLRSTVEVQKYLNDNSEYIGEGVKLSQFSFQIPKPLQDDYVRKRPARLLDSIDNTNTPVAKEANPLAWISPDDHISLQLGTPTESGLNNSHYQPSKKKKTSTLSIFGSNDELAD'\n b'MALLTAAARLFGAKNASCLVLAARHASASSTNLKDILADLIPKEQARIKTFRQQHGNTVVGQITVDMMYGGMRGMKGLVYETSVLDPDEGIRFRGYSIPECQKMLPKAKGGEEPLPEGLFWLLVTGQIPTEEQVSWLSKEWAKRAALPSHVVTMLDNFPTNLHPMSQLSAAITALNSESNFARAYAEGIHRTKYWELIYEDCMDLIAKLPCVAAKIYRNLYREGSSIGAIDSKLDWSHNFTNMLGYTDAQFTELMRLYLTIHSDHEGGNVSAHTSHLVGSALSDPYLSFAAAMNGLAGPLGGLANQEVLVWLTQLQKEVGKDVSDEKLRDYIWNTLNSGRVVPGYGHAVLRKTDPRYTCQREFALKHLPHDPMFKLVAQLYKIVPNVLLEQGKAKNPWPNVDAHSGVLLQYYGMTEMNYYTVLFGVSRALGVLAQLIWSRALGFPLERPKSMSTDGLIKLVDSK'\n b'MSGKVVLHYFNGRGKMESIRWLLAAAGVQFEEVFLTEKEQFDKLLSDGALTFQQVPLVEIDGMKLVQSKAILNYIAGKYNLYGKDLKERAMIDIYSEGLIDLMEMIMVSPFTPAENKEKVFSNIEEKAKVRFLPVFEKALANSSFLVGKQLSRADVHLLEATLMLQELFPSILATFPKIQAFQEQMKALPAISKFLQPGSARKPPPDEEYARTVKAVLSHLF'\n b'MYNIPDNVKGAVEFDPWLKPFADVLSERRYLADKWLYDITHATPDGSYQSLSKFARDSYKSYGLHANPETKEITYKEWAPNAERAFLVGDFNNWDTTSHELKNKDEFGNFTITLHPLPNGDFAIPHDSKIKVMFILPDGSKIFRLPAWITRATQPSKETSKQFGPAYEGRFWNPENPYKFVHPRPKFSESVDSLRIYEAHVGISSPEPKITTYKEFTEKVLPRIKYLGYDAIQLMAIMEHAYYASFGYQVTNFFAASSRFGTPEELKELIDTAHSMGILVLLDVVHSHASKNVEDGLNMFDGSDHQYFHSISSGRGEHPLWDSRLFNYGKFEVQRFLLANLAFYVDVYQFDGFRFDGVTSMLYVHHGVGAGGSFSGDYNEYLSRDRSFVDHEALAYLMLANDLVHEMLPNLAVTVAEDVSGYPTLCLPRSIGGTGFDYRLAMALPDMWIKLIKEKKDDEWEMGSIVYTLTNRRYGEKVVAYCESHDQALVGDKTLAFWLMDAAMYTDMTVLKEPSIVIDRGIALHKMIRLITHSLGGEAYLNFEGNEFGHPEWLDFPNVNNGDSYKYARRQFNLADDPLLRYQNLNEFDRSMQLCEKRHKWLNTKQAYVSLKHEGDKMIVFERNNLLFIFNFHPTNSYSDYRVGVEKAGTYHIVLNSDRAEFGGHNRINESSEFFTTDLEWNNRKNFLQVYIPSRVALVLALK'], shape=(4,), dtype=string)\ntf.Tensor([47.6 56.  46.5 53.5], shape=(4,), dtype=float64)\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 23:43:53.236425: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 95, Output num: 1\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1670370233.236315487\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 95, Output num: 1\",\"grpc_status\":3}\n","output_type":"stream"}]},{"cell_type":"code","source":"model_checkpoint_callback = keras.callbacks.ModelCheckpoint(CHECKPOINT_PATH,\n                                                           monitor='val_loss',\n                                                           save_best_only=True,\n                                                           save_weights_only=True)\n\nearlystop_callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                  patience=10,\n                                                  verbose=1)\n\nreducelr_callback = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                     factor=0.2,\n                                                     patience=5,\n                                                     verbose=1)\n\n# define your custom callback for prediction\nclass CustomCallback(keras.callbacks.Callback):\n    def __init__(self, model, x_test):\n        self.model = model\n        self.x_test = x_test\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred = self.model.predict(self.x_test)\n        print('y predicted: ', y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:53.244983Z","iopub.execute_input":"2022-12-06T23:43:53.245314Z","iopub.status.idle":"2022-12-06T23:43:53.253431Z","shell.execute_reply.started":"2022-12-06T23:43:53.245274Z","shell.execute_reply":"2022-12-06T23:43:53.252759Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def build_model(trainable=True,max_len=512):\n    base_model = TFBertForMaskedLM.from_pretrained(\"Rostlab/prot_bert\", from_pt=True)\n    base_model.trainable = trainable\n    #for i in range(6,13):\n    #    base_model.bert.encoder.layer[i].trainable = False\n    input_ids = keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n\n    attention_mask = keras.Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n    base_output = base_model.bert(input_ids=input_ids,attention_mask=attention_mask)\n    last_hidden_state = base_output[0]\n    x = layers.GlobalAveragePooling1D()(last_hidden_state)\n    x = layers.Dense(512, activation='relu')(x)\n    x = layers.Dropout(0.15)(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dropout(0.1)(x)\n    outputs = layers.Dense(1)(x)\n    model = keras.Model(inputs=[input_ids, attention_mask], outputs=outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:53.254307Z","iopub.execute_input":"2022-12-06T23:43:53.254554Z","iopub.status.idle":"2022-12-06T23:43:53.269929Z","shell.execute_reply.started":"2022-12-06T23:43:53.254513Z","shell.execute_reply":"2022-12-06T23:43:53.26903Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nwith strategy.scope():\n\n    model = build_model(trainable=False)  # freeze base model\n\n    model.compile(optimizer=keras.optimizers.Adam(3e-5),\n                loss=keras.losses.MeanSquaredError(),\n                metrics=[keras.losses.MeanAbsoluteError()])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:43:53.27104Z","iopub.execute_input":"2022-12-06T23:43:53.271269Z","iopub.status.idle":"2022-12-06T23:44:47.633761Z","shell.execute_reply.started":"2022-12-06T23:43:53.271243Z","shell.execute_reply":"2022-12-06T23:44:47.632878Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForMaskedLM: ['cls.predictions.decoder.bias']\n- This IS expected if you are initializing TFBertForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertForMaskedLM were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\nattention_mask (InputLayer)     [(None, 512)]        0                                            \n__________________________________________________________________________________________________\nbert (TFBertMainLayer)          TFBaseModelOutputWit 418881536   input_ids[0][0]                  \n                                                                 attention_mask[0][0]             \n__________________________________________________________________________________________________\nglobal_average_pooling1d (Globa (None, 1024)         0           bert[0][0]                       \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 512)          524800      global_average_pooling1d[0][0]   \n__________________________________________________________________________________________________\ndropout_91 (Dropout)            (None, 512)          0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 256)          131328      dropout_91[0][0]                 \n__________________________________________________________________________________________________\ndropout_92 (Dropout)            (None, 256)          0           dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1)            257         dropout_92[0][0]                 \n==================================================================================================\nTotal params: 419,537,921\nTrainable params: 656,385\nNon-trainable params: 418,881,536\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#callbacks = [ \n#    model_checkpoint_callback,\n#    earlystop_callback,\n#    reducelr_callback,\n#    CustomCallback(model, X_test)\n#]\n\n#history = model.fit(train_dataset,\n#                    validation_data=valid_dataset,\n#                    epochs=3,\n#                    callbacks=callbacks,\n#                    steps_per_epoch=y_train.shape[0]//BATCH_SIZE,\n#                   )","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:44:47.636476Z","iopub.execute_input":"2022-12-06T23:44:47.637196Z","iopub.status.idle":"2022-12-06T23:44:47.641876Z","shell.execute_reply.started":"2022-12-06T23:44:47.63715Z","shell.execute_reply":"2022-12-06T23:44:47.640648Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"model.load_weights(CHECKPOINT_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:44:47.643185Z","iopub.execute_input":"2022-12-06T23:44:47.643449Z","iopub.status.idle":"2022-12-06T23:45:13.381383Z","shell.execute_reply.started":"2022-12-06T23:44:47.643419Z","shell.execute_reply":"2022-12-06T23:45:13.380183Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loss = history.history['loss']\n#epoch = range(len(loss) + len(history.history[\"loss\"]))\n\n#plt.plot(epoch, history.history['loss']+history.history[\"loss\"])\n#plt.plot(epoch, history.history['val_loss']+history.history[\"val_loss\"])\n\n#plt.figure()\n#plt.plot(epoch, history.history['mean_absolute_error']+history.history[\"mean_absolute_error\"])\n#plt.plot(epoch, history.history['val_mean_absolute_error']+history.history[\"val_mean_absolute_error\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:45:13.384319Z","iopub.execute_input":"2022-12-06T23:45:13.385013Z","iopub.status.idle":"2022-12-06T23:45:13.391297Z","shell.execute_reply.started":"2022-12-06T23:45:13.384961Z","shell.execute_reply":"2022-12-06T23:45:13.389864Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(X_test,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:45:13.393275Z","iopub.execute_input":"2022-12-06T23:45:13.39388Z","iopub.status.idle":"2022-12-06T23:45:51.465227Z","shell.execute_reply.started":"2022-12-06T23:45:13.393828Z","shell.execute_reply":"2022-12-06T23:45:51.464158Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"76/76 [==============================] - 36s 380ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"submission_df = pd.DataFrame()\nsubmission_df[\"seq_id\"] = df_test[\"seq_id\"]\nsubmission_df[\"tm\"] = predictions\nsubmission_df.to_csv(\"submission.csv\", index=False)\npd.read_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:45:51.466663Z","iopub.execute_input":"2022-12-06T23:45:51.466928Z","iopub.status.idle":"2022-12-06T23:45:51.50315Z","shell.execute_reply.started":"2022-12-06T23:45:51.466898Z","shell.execute_reply":"2022-12-06T23:45:51.502183Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"      seq_id         tm\n0      31390  50.492134\n1      31391  50.526585\n2      31392  51.242348\n3      31393  50.436428\n4      31394  51.648514\n...      ...        ...\n2408   33798  51.826714\n2409   33799  51.081070\n2410   33800  51.122272\n2411   33801  51.052376\n2412   33802  52.614790\n\n[2413 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seq_id</th>\n      <th>tm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31390</td>\n      <td>50.492134</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>31391</td>\n      <td>50.526585</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31392</td>\n      <td>51.242348</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31393</td>\n      <td>50.436428</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>31394</td>\n      <td>51.648514</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2408</th>\n      <td>33798</td>\n      <td>51.826714</td>\n    </tr>\n    <tr>\n      <th>2409</th>\n      <td>33799</td>\n      <td>51.081070</td>\n    </tr>\n    <tr>\n      <th>2410</th>\n      <td>33800</td>\n      <td>51.122272</td>\n    </tr>\n    <tr>\n      <th>2411</th>\n      <td>33801</td>\n      <td>51.052376</td>\n    </tr>\n    <tr>\n      <th>2412</th>\n      <td>33802</td>\n      <td>52.614790</td>\n    </tr>\n  </tbody>\n</table>\n<p>2413 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(submission_df.tm, bins=100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-06T23:45:51.504442Z","iopub.execute_input":"2022-12-06T23:45:51.5048Z","iopub.status.idle":"2022-12-06T23:45:51.928769Z","shell.execute_reply.started":"2022-12-06T23:45:51.504761Z","shell.execute_reply":"2022-12-06T23:45:51.927632Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}